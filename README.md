# Laboratorio-2-se침ales-
>  Problema del coctel 
---

Septiembre 2024

## Tabla de contenidos
* [쯈u칠 se va a realizar?](#introduccion)
* [Problema del coctel](#problema)
* [Configuracion del sistema](#configuracion)
* [Librerias](#librerias)
* [Cargar audios de voces y rudios](#carga)
* [Graficas de onda del audio](#onda)
* [Espectro de frecuencia](#espectro)
* [Mezcla archivos de audio](#mezcla)
* [Uso de ICA y separacion](#ica)
* [Calculo SNR](#snr)
* [Menu](#menu)
* [Analisis](#analisis)
* [Contacto](#contacto)
---
<a name="introduccion"></a> 
## 쯈u칠 se va a realizar?

En un evento tipo coctel, se instalaron varios micr칩fonos para escuchar lo que las personas estaban hablando; una vez termin칩 la fiesta, se solicit칩 a los 
ingenieros que entregaran el audio de la voz de uno de los participantes. Los ingenieros analizaron las se침ales grabadas por los micr칩fonos eran mezclas 
de se침ales que proven칤an de diferentes fuentes (personas) para todos los casos y se encontraron con el problema de aislar la voz de inter칠s. 

El problema de la "fiesta de c칩ctel" se refiere a la capacidad de un sistema para concentrarse en una sola fuente sonora mientras filtra las dem치s en un entorno con m칰ltiples emisores de sonido. Este problema es com칰n en sistemas de audici칩n tanto humanos como artificiales, y su resoluci칩n es esencial en 
aplicaciones como la mejora de la voz, el reconocimiento de habla y la cancelaci칩n de ruido. 

Para este laboratorio, los estudiantes recrear치n el problema de la fiesta de coctel, donde existen 洧녵 fuentes sonoras capturadas por un arreglo de 洧녵 
micr칩fonos de acuerdo con la siguiente metodolog칤a. 
1. Configuraci칩n del sistema: 
- Conecta los tres micr칩fonos al sistema de adquisici칩n de datos y distribuy칠ndolos estrat칠gicamente en la sala. Los micr칩fonos deben estar ubicados de manera que cada uno capture diferentes combinaciones de las se침ales provenientes de las tres fuentes.
- Ubicar tres personas en posiciones fijas dentro de la sala de laboratorio.
- Deben estar localizados a distancias diferentes y orientados en distintas direcciones para simular un entorno de "fiesta de c칩ctel". 
2. Captura de la se침al:
- Generar la se침al mediante la voz de los tres sujetos de prueba; cada uno debe decir una frase diferente durante el tiempo de captura de la se침al. Las se침ales de los micr칩fonos deben ser registradas por el sistema de adquisici칩n y guardas para ser analizadas.
- Grabar el ruido de la sala con los 3 micr칩fonos y calcular el SNR de cada se침al. Repetir la medici칩n en caso de que el SNR de alguna de las se침ales 
no sea suficiente. Argumentar las razones. 
3. Procesamiento de se침ales: 
- Realizar un an치lisis temporal y espectral de las se침ales capturadas por cada micr칩fono, identificando las caracter칤sticas principales de cada fuente
sonora. Para realizar el an치lisis espectral, se recomienda utilizar la transformada de Fourier discreta (DFT) o la transformada r치pida de Fourier (FFT),
describiendo la informaci칩n que se puede obtener con cada una de ellas.
- Investigar los m칠todos de separaci칩n de fuentes, como el An치lisis de Componentes Independientes (ICA), el Beamforming, entre otros, para aislar 
la se침al de inter칠s a partir de las se침ales capturadas por los micr칩fonos.  
4. Evaluar los resultados comparando la se침al aislada con la se침al original utilizado m칠tricas de calidad como la relaci칩n se침al/ruido para cuantificar el desempe침o de la separaci칩n. 

<a name="problema"></a> 
## Problema del coctel

El efecto de fiesta de c칩ctel es un fen칩meno que consiste en enfocar la atenci칩n auditiva en un est칤mulo ac칰stico en particular, mientras se trata de filtrar y eliminar el resto de est칤mulos que pueden actuar como distractores.El nombre de este fen칩meno es bastante representativo del efecto, dado que, si lo pensamos, en una fiesta, cuando estamos hablando con alg칰n invitado, tratamos de filtrar lo que nos est치 diciendo e ignorando la m칰sica y otras conversaciones que puedan estar transcurriendo de forma simult치nea, conformando el fondo.

Gracias a este fen칩meno, somos capaces de diferenciar entre la voz de la persona con quien estamos manteniendo la conversaci칩n de la del resto de personas que puedan estar conformando el fondo ac칰stico del ambiente en el que nos estamos encontrando.Este mismo fen칩meno tambi칠n es el que permite que, sin estar del todo concentrado en otras conversaciones, seamos capaces de captar la atenci칩n cuando se menciona una palabra que nos resulta importante, como puede ser el que nos llamen por nuestro nombre.

<a name="configuracion"></a> 
## Configuracion del sistema

En este caso como fue mencionado en la introduccion se debia realizar con 3 personas, en un inicio el laboratorio si se hizo de esa manera pero los audios tomados fueron de un tiempo muy bajo (1 segundo), por esta razon al no obtener un buen muestro decidio realizarse una nueva toma con 2 personas de  la siguiente manera:

Las personas se organizaron una en frente de la otra con una distancia de 27,9 cm equivalemte a lo que mide una hoja carta de largo desde los pies de la persona 1 al celular 1, luego otra hoja desde el celular 1 al celular 2 y una ultima hoja desde el celular 2 a la persona 2. 

![Agregar](captura.jpg)

La grabacion se realizo en este caso por medio una aplicacion llamada "Grabadora de Voz" la cual la podemos encontrar en app store, esto para asegurar que la frecuencia de muestreo que utilizaramos sea la misma.

![Agregar](grabadora.jpg)

Para la grabacion la frecuencia de muestreo fue de 16 kHz en cada celular, se grabaron 4 segundos del ruido del ambiente y 4 segundos a las personas hablando.

![Agregar](frecuencia.jpg)

1. Audios persona 1  (Mariana):


https://github.com/user-attachments/assets/e087082f-2b14-4eb6-b42e-ab8e2317dc59

Dialogo: Mi nombre es Mariana Higuera, tengo 18 a침os y mi mam치 se llama Lilian Caicedo.

https://github.com/user-attachments/assets/cd83c1c9-4014-4715-8696-32f6dae8d133

2. Audio persona 2 (Mam치):

https://github.com/user-attachments/assets/880810c3-7b88-43a7-87cd-1a991a7554f7

Dialogo: Mi mam치 se llama Lilia Vasquez, yo tengo 51 a침os y mi nombre es Lilian Caicedo.

https://github.com/user-attachments/assets/ca4394b2-ae84-47e0-8e82-1a0b656d8360

<a name="librerias"></a> 
## Librerias
```c
import matplotlib.pyplot as plt
import numpy as np
import librosa
import sounddevice as sd
from sklearn.decomposition import FastICA
```
1. Librosa: Es una biblioteca especializada en el procesamiento de se침ales de audio. Es ampliamente utilizada para tareas como la extracci칩n de caracter칤sticas de audio, la generaci칩n de espectrogramas, y la manipulaci칩n de archivos de audio.

2. SoundDevice: Es una biblioteca que permite la grabaci칩n y reproducci칩n de audio directamente desde Python usando dispositivos de audio.

3. FastICA (de sklearn.decomposition): Es una implementaci칩n del algoritmo de An치lisis de Componentes Independientes (ICA) en la biblioteca scikit-learn. ICA es una t칠cnica de separaci칩n de fuentes ciega (BSS) que intenta descomponer una se침al multivariable en componentes estad칤sticamente independientes.

- Compatibilidad y Estandarizaci칩n: .wav es un formato ampliamente compatible con diversas herramientas y bibliotecas de procesamiento de audio, incluidas librosa y sounddevice, que se utilizan en este c칩digo. Esto asegura que no haya problemas de compatibilidad al cargar o reproducir archivos de audio.

<a name="carga"></a> 
## Cargar audios de voces y ruidos

Este c칩digo est치 dise침ado para trabajar con archivos de audio, espec칤ficamente para cargar y reproducir grabaciones de voces y ruidos almacenados en archivos de formato `.wav`. El c칩digo comienza definiendo dos listas, `audio_voces` y `audio_ruido`, que contienen los nombres de los archivos de audio correspondientes a las voces y ruidos que se desean manipular.

A continuaci칩n, se define una funci칩n llamada `loadAudio`, que utiliza la biblioteca `librosa` para cargar un archivo de audio. Esta funci칩n toma como par치metro el nombre o la ruta de un archivo de audio y devuelve dos cosas: un array NumPy que contiene los datos de la se침al de audio y la tasa de muestreo con la que fue grabado el archivo. La tasa de muestreo es la cantidad de muestras por segundo que se toman del audio, y se mantiene intacta (sin cambios) al cargar el archivo.

La otra funci칩n, `playAudio`, se encarga de reproducir el audio que ha sido cargado. Esta funci칩n utiliza la biblioteca `sounddevice` para enviar los datos de audio al dispositivo de salida, como los altavoces o auriculares. La funci칩n recibe los datos de audio y la tasa de muestreo, los cuales son necesarios para que la reproducci칩n sea precisa. Adem치s, se incluye un comando para esperar hasta que la reproducci칩n del audio haya terminado antes de proceder con cualquier otra operaci칩n en el c칩digo.

```c
# Archivos de voces y ruidos ya cargados
audio_voces = ["voz_mama.wav", "voz_mari.wav"]
audio_ruido = ["Ruidomama.wav", "ruidomari.wav"]

# Funci칩n para cargar un archivo de audio
def loadAudio(archivo):
    data, samplerate = librosa.load(archivo, sr=None)  # Carga el archivo de audio sin cambio de tasa de muestreo
    return data, samplerate

# Funci칩n para reproducir un audio
def playAudio(data, sr):
    sd.play(data, sr)  # Reproduce el audio
    sd.wait()  # Espera a que termine la reproducci칩n
```

<a name="onda"></a> 
## Graficas de onda del audio

La funci칩n `graficarSonido` est치 dise침ada para crear una visualizaci칩n de la forma de onda de un archivo de audio. En primer lugar, la funci칩n calcula el tiempo en segundos para cada muestra de audio. Esto se realiza generando un array de 칤ndices que representan cada muestra en el archivo y dividiendo estos 칤ndices por la tasa de muestreo, `sr`. El resultado es un array que indica el tiempo correspondiente a cada muestra, permitiendo que el eje x del gr치fico represente el tiempo en segundos.

Luego, la funci칩n crea una figura de tama침o 12x6 pulgadas para la visualizaci칩n. Utiliza `matplotlib` para graficar los datos de audio, donde el eje x muestra el tiempo y el eje y muestra la amplitud de la se침al. La l칤nea del gr치fico se dibuja en color azul con un grosor de 1.5 puntos. Para enfocar la visualizaci칩n, el eje x se limita a los primeros 2 segundos del audio, lo que es 칰til si se desea examinar solo una parte espec칤fica de la se침al.

```c
# Funci칩n para graficar la forma de onda del audio
def graficarSonido(data, sr, title=""):
    t = np.arange(len(data)) / sr  # Calcula el tiempo en segundos
    plt.figure(figsize=(12, 6))  # Tama침o de la figura
    plt.plot(t, data, color='royalblue', lw=1.5)  # Grafica la forma de onda en color azul
    plt.xlim(0, 2)  # Limita el eje x a los primeros 2 segundos
    plt.xlabel('Tiempo (s)')
    plt.ylabel('Amplitud')
    plt.title(title)
    plt.grid(True, linestyle='--', alpha=0.7)  # A침ade una cuadr칤cula punteada
    plt.show()
```

<a name="espectro"></a> 
## Espectro de frecuencia

La funci칩n `analisisEspectral` est치 dise침ada para analizar y visualizar el espectro de frecuencias de una se침al de audio. Primero, la funci칩n calcula el n칰mero total de muestras del audio mediante `n = len(data)`. Tambi칠n determina el intervalo de muestreo `T`, que es el inverso de la tasa de muestreo `sr`, indicando el tiempo entre cada muestra.

La funci칩n luego aplica la Transformada R치pida de Fourier (FFT) a los datos de audio con `np.fft.fft(data)`. La FFT convierte la se침al del dominio del tiempo al dominio de la frecuencia, permitiendo analizar las frecuencias presentes en el audio. Para obtener las frecuencias correspondientes a la FFT, se usa `np.fft.fftfreq(n, T)`, y se toma solo la primera mitad de las frecuencias (`[:n // 2]`), ya que la FFT produce una imagen sim칠trica en el dominio de la frecuencia.

- Transformada r치pida de Fourier FFT: Es un algoritmo utilizado para calcular la transformada discreta de Fourier (DFT) y su inversa de manera m치s eficiente. La DFT es una transformada utilizada en el procesamiento de se침ales y de im치genes, entre muchas otras 치reas, para transformar una se침al discreta en su representaci칩n en el dominio de la frecuencia. La FFT acelera el proceso de c치lculo de la DFT, lo que permite su uso en aplicaciones en tiempo real y para grandes conjuntos de datos.

```c
# Funci칩n para analizar el espectro de frecuencias del audio
def analisisEspectral(data, sr, title="Espectro de frecuencias del audio"):
    n = len(data)  # N칰mero de muestras
    T = 1 / sr  # Intervalo de muestreo
    yf = np.fft.fft(data)  # Transformada de Fourier del audio
    xf = np.fft.fftfreq(n, T)[:n // 2]  # Frecuencias correspondientes a la FFT
    
    plt.figure(figsize=(12, 6))  # Tama침o de la figura
    plt.plot(xf, 2.0 / n * np.abs(yf[:n // 2]), color='darkorange', lw=1.5)  # Grafica el espectro en color naranja
    plt.xlim(0, 2000)  # Limita el eje x a 2000 Hz
    plt.xlabel('Frecuencia (Hz)')
    plt.ylabel('Amplitud')
    plt.title(title)
    plt.grid(True, linestyle='--', alpha=0.7)  # A침ade una cuadr칤cula punteada
    plt.show()
```

<a name="mezcla"></a> 
## Mezcla archivos de audio



```c

```

<a name="ica"></a> 
## Uso de ICA y separacion

```c

```

<a name="snr"></a> 
## Calculo SNR

```c

```

<a name="menu"></a> 
## Menu

```c

```

<a name="analisis"></a> 
## Analisis

```c

```

<a name="contacto"></a> 
## Contacto
* Creado por [Marianitex](https://github.com/Marianitex) - s칤gueme en mis redes sociales como @_mariana.higuera












# Laboratorio-2-se침ales-
>  Problema del coctel 
---

Septiembre 2024

## Tabla de contenidos
* [쯈u칠 se va a realizar?](#introduccion)
* [Problema del coctel](#problema)
* [Configuracion del sistema](#configuracion)
* [Librerias](#librerias)
* [Cargar audios de voces y rudios](#carga)
* [Graficas de onda del audio](#onda)
* [Espectro de frecuencia](#espectro)
* [Mezcla archivos de audio](#mezcla)
* [Uso de ICA, separacion y SNR relacion se침al-ruido](#ica)
* [Calculo SNR voces separadas](#snr)
* [Menu](#menu)
* [Analisis](#analisis)
* [Contacto](#contacto)
---
<a name="introduccion"></a> 
## 쯈u칠 se va a realizar?

En un evento tipo coctel, se instalaron varios micr칩fonos para escuchar lo que las personas estaban hablando; una vez termin칩 la fiesta, se solicit칩 a los 
ingenieros que entregaran el audio de la voz de uno de los participantes. Los ingenieros analizaron las se침ales grabadas por los micr칩fonos eran mezclas 
de se침ales que proven칤an de diferentes fuentes (personas) para todos los casos y se encontraron con el problema de aislar la voz de inter칠s. 

El problema de la "fiesta de c칩ctel" se refiere a la capacidad de un sistema para concentrarse en una sola fuente sonora mientras filtra las dem치s en un entorno con m칰ltiples emisores de sonido. Este problema es com칰n en sistemas de audici칩n tanto humanos como artificiales, y su resoluci칩n es esencial en 
aplicaciones como la mejora de la voz, el reconocimiento de habla y la cancelaci칩n de ruido. 

Para este laboratorio, los estudiantes recrear치n el problema de la fiesta de coctel, donde existen 洧녵 fuentes sonoras capturadas por un arreglo de 洧녵 
micr칩fonos de acuerdo con la siguiente metodolog칤a. 
1. Configuraci칩n del sistema: 
- Conecta los tres micr칩fonos al sistema de adquisici칩n de datos y distribuy칠ndolos estrat칠gicamente en la sala. Los micr칩fonos deben estar ubicados de manera que cada uno capture diferentes combinaciones de las se침ales provenientes de las tres fuentes.
- Ubicar tres personas en posiciones fijas dentro de la sala de laboratorio.
- Deben estar localizados a distancias diferentes y orientados en distintas direcciones para simular un entorno de "fiesta de c칩ctel". 
2. Captura de la se침al:
- Generar la se침al mediante la voz de los tres sujetos de prueba; cada uno debe decir una frase diferente durante el tiempo de captura de la se침al. Las se침ales de los micr칩fonos deben ser registradas por el sistema de adquisici칩n y guardas para ser analizadas.
- Grabar el ruido de la sala con los 3 micr칩fonos y calcular el SNR de cada se침al. Repetir la medici칩n en caso de que el SNR de alguna de las se침ales 
no sea suficiente. Argumentar las razones. 
3. Procesamiento de se침ales: 
- Realizar un an치lisis temporal y espectral de las se침ales capturadas por cada micr칩fono, identificando las caracter칤sticas principales de cada fuente
sonora. Para realizar el an치lisis espectral, se recomienda utilizar la transformada de Fourier discreta (DFT) o la transformada r치pida de Fourier (FFT),
describiendo la informaci칩n que se puede obtener con cada una de ellas.
- Investigar los m칠todos de separaci칩n de fuentes, como el An치lisis de Componentes Independientes (ICA), el Beamforming, entre otros, para aislar 
la se침al de inter칠s a partir de las se침ales capturadas por los micr칩fonos.  
4. Evaluar los resultados comparando la se침al aislada con la se침al original utilizado m칠tricas de calidad como la relaci칩n se침al/ruido para cuantificar el desempe침o de la separaci칩n. 

<a name="problema"></a> 
## Problema del coctel

El efecto de fiesta de c칩ctel es un fen칩meno que consiste en enfocar la atenci칩n auditiva en un est칤mulo ac칰stico en particular, mientras se trata de filtrar y eliminar el resto de est칤mulos que pueden actuar como distractores.El nombre de este fen칩meno es bastante representativo del efecto, dado que, si lo pensamos, en una fiesta, cuando estamos hablando con alg칰n invitado, tratamos de filtrar lo que nos est치 diciendo e ignorando la m칰sica y otras conversaciones que puedan estar transcurriendo de forma simult치nea, conformando el fondo.

Gracias a este fen칩meno, somos capaces de diferenciar entre la voz de la persona con quien estamos manteniendo la conversaci칩n de la del resto de personas que puedan estar conformando el fondo ac칰stico del ambiente en el que nos estamos encontrando.Este mismo fen칩meno tambi칠n es el que permite que, sin estar del todo concentrado en otras conversaciones, seamos capaces de captar la atenci칩n cuando se menciona una palabra que nos resulta importante, como puede ser el que nos llamen por nuestro nombre.

<a name="configuracion"></a> 
## Configuracion del sistema

En este caso como fue mencionado en la introduccion se debia realizar con 3 personas, en un inicio el laboratorio si se hizo de esa manera pero los audios tomados fueron de un tiempo muy bajo (1 segundo), por esta razon al no obtener un buen muestro decidio realizarse una nueva toma con 2 personas de  la siguiente manera:

Las personas se organizaron una en frente de la otra con una distancia de 27,9 cm equivalemte a lo que mide una hoja carta de largo desde los pies de la persona 1 al celular 1, luego otra hoja desde el celular 1 al celular 2 y una ultima hoja desde el celular 2 a la persona 2. 

![Agregar](captura.jpg)

La grabacion se realizo en este caso por medio una aplicacion llamada "Grabadora de Voz" la cual la podemos encontrar en app store, esto para asegurar que la frecuencia de muestreo que utilizaramos sea la misma.

![Agregar](grabadora.jpg)

Para la grabacion la frecuencia de muestreo fue de 16 kHz en cada celular, se grabaron 4 segundos del ruido del ambiente y 4 segundos a las personas hablando.

![Agregar](frecuencia.jpg)

1. Audios persona 1  (Mariana):


https://github.com/user-attachments/assets/e087082f-2b14-4eb6-b42e-ab8e2317dc59

Dialogo: Mi nombre es Mariana Higuera, tengo 18 a침os y mi mam치 se llama Lilian Caicedo.

https://github.com/user-attachments/assets/cd83c1c9-4014-4715-8696-32f6dae8d133

2. Audio persona 2 (Mam치):

https://github.com/user-attachments/assets/880810c3-7b88-43a7-87cd-1a991a7554f7

Dialogo: Mi mam치 se llama Lilia Vasquez, yo tengo 51 a침os y mi nombre es Lilian Caicedo.

https://github.com/user-attachments/assets/ca4394b2-ae84-47e0-8e82-1a0b656d8360

<a name="librerias"></a> 
## Librerias
```c
import matplotlib.pyplot as plt
import numpy as np
import librosa
import sounddevice as sd
from sklearn.decomposition import FastICA
```
1. Librosa: Es una biblioteca especializada en el procesamiento de se침ales de audio. Es ampliamente utilizada para tareas como la extracci칩n de caracter칤sticas de audio, la generaci칩n de espectrogramas, y la manipulaci칩n de archivos de audio.

2. SoundDevice: Es una biblioteca que permite la grabaci칩n y reproducci칩n de audio directamente desde Python usando dispositivos de audio.

3. FastICA (de sklearn.decomposition): Es una implementaci칩n del algoritmo de An치lisis de Componentes Independientes (ICA) en la biblioteca scikit-learn. ICA es una t칠cnica de separaci칩n de fuentes ciega (BSS) que intenta descomponer una se침al multivariable en componentes estad칤sticamente independientes.

- Compatibilidad y Estandarizaci칩n: .wav es un formato ampliamente compatible con diversas herramientas y bibliotecas de procesamiento de audio, incluidas librosa y sounddevice, que se utilizan en este c칩digo. Esto asegura que no haya problemas de compatibilidad al cargar o reproducir archivos de audio.

<a name="carga"></a> 
## Cargar audios de voces y ruidos

Este c칩digo est치 dise침ado para trabajar con archivos de audio, espec칤ficamente para cargar y reproducir grabaciones de voces y ruidos almacenados en archivos de formato `.wav`. El c칩digo comienza definiendo dos listas, `audio_voces` y `audio_ruido`, que contienen los nombres de los archivos de audio correspondientes a las voces y ruidos que se desean manipular.

A continuaci칩n, se define una funci칩n llamada `loadAudio`, que utiliza la biblioteca `librosa` para cargar un archivo de audio. Esta funci칩n toma como par치metro el nombre o la ruta de un archivo de audio y devuelve dos cosas: un array NumPy que contiene los datos de la se침al de audio y la tasa de muestreo con la que fue grabado el archivo. La tasa de muestreo es la cantidad de muestras por segundo que se toman del audio, y se mantiene intacta (sin cambios) al cargar el archivo.

La otra funci칩n, `playAudio`, se encarga de reproducir el audio que ha sido cargado. Esta funci칩n utiliza la biblioteca `sounddevice` para enviar los datos de audio al dispositivo de salida, como los altavoces o auriculares. La funci칩n recibe los datos de audio y la tasa de muestreo, los cuales son necesarios para que la reproducci칩n sea precisa. Adem치s, se incluye un comando para esperar hasta que la reproducci칩n del audio haya terminado antes de proceder con cualquier otra operaci칩n en el c칩digo.

```c
# Archivos de voces y ruidos ya cargados
audio_voces = ["voz_mama.wav", "voz_mari.wav"]
audio_ruido = ["Ruidomama.wav", "ruidomari.wav"]

# Funci칩n para cargar un archivo de audio
def loadAudio(archivo):
    data, samplerate = librosa.load(archivo, sr=None)  # Carga el archivo de audio sin cambio de tasa de muestreo
    return data, samplerate

# Funci칩n para reproducir un audio
def playAudio(data, sr):
    sd.play(data, sr)  # Reproduce el audio
    sd.wait()  # Espera a que termine la reproducci칩n
```

<a name="onda"></a> 
## Graficas de onda del audio

La funci칩n `graficarSonido` est치 dise침ada para crear una visualizaci칩n de la forma de onda de un archivo de audio. En primer lugar, la funci칩n calcula el tiempo en segundos para cada muestra de audio. Esto se realiza generando un array de 칤ndices que representan cada muestra en el archivo y dividiendo estos 칤ndices por la tasa de muestreo, `sr`. El resultado es un array que indica el tiempo correspondiente a cada muestra, permitiendo que el eje x del gr치fico represente el tiempo en segundos.

Luego, la funci칩n crea una figura de tama침o 12x6 pulgadas para la visualizaci칩n. Utiliza `matplotlib` para graficar los datos de audio, donde el eje x muestra el tiempo y el eje y muestra la amplitud de la se침al. La l칤nea del gr치fico se dibuja en color azul con un grosor de 1.5 puntos. Para enfocar la visualizaci칩n, el eje x se limita a los primeros 2 segundos del audio, lo que es 칰til si se desea examinar solo una parte espec칤fica de la se침al.

```c
# Funci칩n para graficar la forma de onda del audio
def graficarSonido(data, sr, title=""):
    t = np.arange(len(data)) / sr  # Calcula el tiempo en segundos
    plt.figure(figsize=(12, 6))  # Tama침o de la figura
    plt.plot(t, data, color='royalblue', lw=1.5)  # Grafica la forma de onda en color azul
    plt.xlim(0, 2)  # Limita el eje x a los primeros 2 segundos
    plt.xlabel('Tiempo (s)')
    plt.ylabel('Amplitud')
    plt.title(title)
    plt.grid(True, linestyle='--', alpha=0.7)  # A침ade una cuadr칤cula punteada
    plt.show()
```

![Agregar](ondamama.png)

![Agregar](ondamari.png)

<a name="espectro"></a> 
## Espectro de frecuencia

La funci칩n `analisisEspectral` est치 dise침ada para analizar y visualizar el espectro de frecuencias de una se침al de audio. Primero, la funci칩n calcula el n칰mero total de muestras del audio mediante `n = len(data)`. Tambi칠n determina el intervalo de muestreo `T`, que es el inverso de la tasa de muestreo `sr`, indicando el tiempo entre cada muestra.

La funci칩n luego aplica la Transformada R치pida de Fourier (FFT) a los datos de audio con `np.fft.fft(data)`. La FFT convierte la se침al del dominio del tiempo al dominio de la frecuencia, permitiendo analizar las frecuencias presentes en el audio. Para obtener las frecuencias correspondientes a la FFT, se usa `np.fft.fftfreq(n, T)`, y se toma solo la primera mitad de las frecuencias (`[:n // 2]`), ya que la FFT produce una imagen sim칠trica en el dominio de la frecuencia.

- Transformada r치pida de Fourier FFT: Es un algoritmo utilizado para calcular la transformada discreta de Fourier (DFT) y su inversa de manera m치s eficiente. La DFT es una transformada utilizada en el procesamiento de se침ales y de im치genes, entre muchas otras 치reas, para transformar una se침al discreta en su representaci칩n en el dominio de la frecuencia. La FFT acelera el proceso de c치lculo de la DFT, lo que permite su uso en aplicaciones en tiempo real y para grandes conjuntos de datos.

```c
# Funci칩n para analizar el espectro de frecuencias del audio
def analisisEspectral(data, sr, title="Espectro de frecuencias del audio"):
    n = len(data)  # N칰mero de muestras
    T = 1 / sr  # Intervalo de muestreo
    yf = np.fft.fft(data)  # Transformada de Fourier del audio
    xf = np.fft.fftfreq(n, T)[:n // 2]  # Frecuencias correspondientes a la FFT
    
    plt.figure(figsize=(12, 6))  # Tama침o de la figura
    plt.plot(xf, 2.0 / n * np.abs(yf[:n // 2]), color='darkorange', lw=1.5)  # Grafica el espectro en color naranja
    plt.xlim(0, 2000)  # Limita el eje x a 2000 Hz
    plt.xlabel('Frecuencia (Hz)')
    plt.ylabel('Amplitud')
    plt.title(title)
    plt.grid(True, linestyle='--', alpha=0.7)  # A침ade una cuadr칤cula punteada
    plt.show()
```

![Agregar](espectromama.png)

![Agregar](espectromari.png)

<a name="mezcla"></a> 
## Mezcla archivos de audio

La funci칩n `mezclarVoces` est치 dise침ada para combinar dos archivos de audio en una sola se침al, permitiendo mezclarlos para obtener una mezcla de las dos grabaciones. 

Primero, la funci칩n carga los datos de ambos archivos de audio utilizando la funci칩n `loadAudio`. Esto se realiza llamando a `loadAudio(audio1)` y `loadAudio(audio2)`, lo que devuelve dos conjuntos de datos de audio y la tasa de muestreo (`sr`). La tasa de muestreo es la misma para ambos archivos, ya que `loadAudio` se encargar치 de mantener la tasa original.

Luego, la funci칩n asegura que ambas se침ales de audio tengan la misma longitud para evitar problemas en el procesamiento posterior. Calcula la longitud m칤nima entre las dos se침ales usando `min(len(data1), len(data2))` y ajusta ambas se침ales a esta longitud. Esto garantiza que tanto `data1` como `data2` tengan el mismo n칰mero de muestras al recortar el exceso de datos en la se침al m치s larga.

Las se침ales ajustadas se almacenan en una lista llamada `signals`. Luego, se utiliza `np.vstack(signals)` para apilar las dos se침ales en una matriz, donde cada fila representa una de las se침ales. Finalmente, la matriz se transpone con `mixed_signals.T` para que cada se침al ocupe una columna en lugar de una fila.

El resultado de la funci칩n es una matriz en la que cada columna corresponde a una de las se침ales originales mezcladas, y se devuelve junto con la tasa de muestreo `sr`. Esta estructura facilita la manipulaci칩n y an치lisis de las se침ales mezcladas, permitiendo trabajar con ambas se침ales simult치neamente en el mismo formato.

```c
# Funci칩n para mezclar dos archivos de audio
def mezclarVoces(audio1, audio2):
    signals = []
    data1, sr = loadAudio(audio1)  # Carga el primer archivo
    data2, sr = loadAudio(audio2)  # Carga el segundo archivo
    
    # Ajusta la longitud para que ambas se침ales tengan el mismo tama침o
    min_len = min(len(data1), len(data2))
    data1 = data1[:min_len]
    data2 = data2[:min_len]
    
    signals.append(data1)
    signals.append(data2)
    
    # Apila las se침ales para mezclarlas
    mixed_signals = np.vstack(signals)
    return mixed_signals.T, sr  # Transpone la matriz para tener las se침ales en columnas
```
- Graficas mezcla y espectro mezcla mama:
- 
![Agregar](mezclamama.png)

![Agregar](espectromezclamama.png)

- Grficas mezcla y espectro mezcla mari:

![Agregar](mezclamari.png)

![Agregar](espectromezclamari.png)

<a name="ica"></a> 
## Uso de ICA, separacion y SNR relacion se침al-ruido

La funci칩n `aplicar_ica` est치 dise침ada para aplicar el An치lisis de Componentes Independientes (ICA) a una se침al de audio con el objetivo de separar las se침ales mezcladas en componentes individuales. Primero, se configura el ICA mediante la creaci칩n de una instancia de `FastICA` con dos componentes (`n_components=2`), que indica que el algoritmo intentar치 separar la se침al en dos componentes independientes. Adem치s, se establecen par치metros como `max_iter=1000` para el n칰mero m치ximo de iteraciones y `tol=0.001` para la tolerancia de convergencia del algoritmo. Luego, se aplica ICA a la se침al usando `ica.fit_transform(signal)`, que devuelve una matriz con las se침ales separadas. La funci칩n finalmente retorna esta matriz, donde cada columna representa una de las se침ales independientes obtenidas.

La funci칩n `potenciaDeSe침al` calcula la potencia de dos se침ales, una de voz y una de ruido. La potencia de una se침al se define como el promedio de los cuadrados de sus valores. Para calcular la potencia de la voz, se utiliza `np.mean(voz**2)`, y para la potencia del ruido, se usa `np.mean(ruido**2)`. Estos c치lculos permiten medir la intensidad de cada se침al en t칠rminos de su energ칤a promedio. La funci칩n retorna dos valores: la potencia de la voz y la potencia del ruido, facilitando la comparaci칩n entre ambos.

La funci칩n `identificar_voz` ayuda a determinar cu치l de las componentes separadas por ICA corresponde a la se침al de voz original. Primero, la funci칩n itera sobre las componentes obtenidas de ICA, graficando cada componente usando las funciones `graficarSonido` y `analisisEspectral` para mostrar la forma de onda y el espectro de frecuencias. Esto proporciona una visualizaci칩n que ayuda al usuario a identificar cu치l componente parece ser la voz. Despu칠s de mostrar las gr치ficas, el usuario debe seleccionar la componente que parece ser la voz a trav칠s de una entrada de texto. La funci칩n verifica si la selecci칩n es v치lida y devuelve la componente seleccionada. Si la selecci칩n no es v치lida, muestra un mensaje de error y retorna `None`. Este proceso permite identificar y extraer la se침al de voz de las componentes separadas.

```c
# Funci칩n para aplicar ICA y separar las se침ales
def aplicar_ica(signal):
    ica = FastICA(n_components=2, max_iter=1000, tol=0.001)  # Configuraci칩n del ICA
    se침ales_separadas = ica.fit_transform(signal)  # Aplica ICA para separar las se침ales
    
    return se침ales_separadas

# Funci칩n para calcular la potencia de la se침al
def potenciaDeSe침al(voz, ruido):
    potencia_voz = np.mean(voz**2)  # Calcula la potencia de la voz
    potencia_ruido = np.mean(ruido**2)  # Calcula la potencia del ruido
    return potencia_voz, potencia_ruido

# Funci칩n para identificar la componente de voz tras aplicar ICA
def identificar_voz(components, sr):
    # Asumimos que la componente m치s cercana a la forma de onda de la voz original es la voz
    for i, component in enumerate(components.T):
        graficarSonido(component, sr, f"Componente {i+1} para identificaci칩n de voz")
        analisisEspectral(component, sr, f"Espectro de la componente {i+1}")
    
    seleccion = int(input("\nSeleccione el n칰mero de la componente que parece ser la voz (1 o 2): ")) - 1
    if seleccion < 0 or seleccion >= len(components.T):
        print("Opci칩n no v치lida.")
        return None
    return components[:, seleccion]  # Devuelve la componente seleccionada
```
El **An치lisis de Componentes Independientes (ICA)** funciona a trav칠s de un proceso matem치tico que busca descomponer una se침al mixta (como una mezcla de sonidos o se침ales de diferentes fuentes) en sus componentes originales, asumiendo que estos componentes son estad칤sticamente independientes entre s칤.

### Pasos fundamentales del funcionamiento del ICA:

1. **Mezcla de se침ales**:
   Cuando diferentes se침ales independientes (por ejemplo, dos personas hablando al mismo tiempo) se capturan con un conjunto de sensores (micr칩fonos), estos capturan una mezcla lineal de todas las se침ales. Matem치ticamente, la mezcla de se침ales se puede expresar como:
   
![Agregar](ica1.png)

   Donde:
   - **X** representa las se침ales observadas (mezcladas) por los sensores.
   - **A** es una matriz de mezcla desconocida que representa c칩mo se combinan las se침ales independientes.
   - **S** son las se침ales originales independientes que queremos recuperar.

1. **Objetivo del ICA**:
   El objetivo del ICA es encontrar una matriz **W** que sea la inversa de la matriz de mezcla **A**, lo que permitir치 obtener las se침ales originales separadas **S** a partir de las se침ales observadas **X**. Esto se logra mediante la ecuaci칩n:
   
![Agregar](ica2.png)
   
   Aqu칤, **W** es la matriz de pesos que ICA calcula para realizar la separaci칩n.

3. **Independencia estad칤stica**:
   La clave del proceso es la suposici칩n de que las se침ales originales **S** son **independientes estad칤sticamente** entre s칤. Esto significa que los valores de una se침al no influyen en los valores de las otras se침ales. Para encontrar **W**, el algoritmo ICA maximiza esta independencia.

4. **Maximizaci칩n de la no-gaussianidad**:
   Una caracter칤stica importante es que ICA maximiza la **no-gaussianidad** de las se침ales separadas. Esto se debe a que, seg칰n el **teorema del l칤mite central**, una mezcla de muchas se침ales independientes tiende a tener una distribuci칩n cercana a la gaussiana (campana). Por lo tanto, para recuperar las se침ales originales, ICA busca aquellas se침ales que son lo m치s no-gaussianas posibles.

5. **Normalizaci칩n y preprocesamiento (whitening)**:
   Antes de aplicar el algoritmo ICA, las se침ales suelen ser **normalizadas** o **blanqueadas** (whitening). Esto significa que las se침ales mezcladas se transforman para tener una **varianza unitaria** y **covarianza cero**, lo que facilita el c치lculo de la matriz de mezcla **W**. Este paso asegura que las componentes tengan independencia, eliminando cualquier correlaci칩n lineal.

6. **Algoritmo iterativo**:
   El ICA se resuelve a menudo a trav칠s de algoritmos iterativos que ajustan gradualmente la matriz **W** hasta que se maximiza la independencia de las se침ales separadas. Algunos de los algoritmos populares utilizados para ICA son **FastICA** y **InfoMax**. Estos m칠todos ajustan los pesos con base en la informaci칩n estad칤stica de las se침ales mezcladas.
- Graficas voz separada y espectro voz separada mama:

![Agregar](vozseparadamama.png)

![Agregar](espectroseparadamama.png)

-SNR para la voz separada: 44.62 dB, es un valor bastante alto que indica una excelente calidad de la se침al de audio. En t칠rminos simples, el SNR mide la relaci칩n entre la intensidad de la se침al deseada (en este caso, la voz) y el nivel de ruido de fondo. Un SNR alto, sugiere que la se침al de voz es mucho m치s fuerte que el ruido, lo que significa que el ruido tiene una presencia m칤nima en la se침al final.

Este nivel de SNR implica que la voz separada es clara y bien distinguible, con poco impacto del ruido. Esto es crucial en aplicaciones de procesamiento de audio y comunicaci칩n, donde es importante mantener la claridad de la voz. En general, los valores de SNR m치s altos corresponden a una mejor calidad de la se침al, con menos interferencia del ruido.

- Graficas voz separada y espectro voz separada mari:

![Agregar](vozseparadamari.png)

![Agregar](espectroseparadamari.png)

-SNR para la voz separada: 45.37 dB, es a칰n mejor que el valor anterior de 44.62 dB, y sigue indicando una calidad de se침al excepcionalmente alta. Este valor sugiere que la se침al de voz es extremadamente clara en comparaci칩n con el nivel de ruido de fondo.

Con un SNR de 45.37 dB, la voz separada es muy n칤tida, con el ruido presente en la se침al siendo casi imperceptible. En t칠rminos pr치cticos, esto significa que la calidad de la se침al de voz es excelente, y el ruido tiene un impacto insignificante, si es que se percibe en absoluto. Este alto SNR es indicativo de una separaci칩n de se침ales muy efectiva y de un procesamiento de audio de alta calidad.

<a name="snr"></a> 
## Calculo SNR voces separadas

La funci칩n `opcion_calcular_snr` tiene como objetivo calcular la relaci칩n se침al-ruido (SNR) para cada par de archivos de audio de voz y ruido, y luego imprimir los resultados correspondientes. 

Primero, la funci칩n comienza con un bucle `for` que itera tres veces, una para cada par de archivos de audio especificado. El 칤ndice `i` se utiliza para acceder a los archivos en las listas `audio_voces` y `audio_ruido`, permitiendo procesar cada par de archivos en la iteraci칩n actual.

Dentro del bucle, la funci칩n carga los datos de audio para la voz y el ruido correspondientes al 칤ndice actual utilizando la funci칩n `loadAudio`. Esta funci칩n devuelve los datos de audio (`voz` y `ruido`) y la tasa de muestreo (`sr`). La tasa de muestreo se mantiene pero no se utiliza en c치lculos posteriores dentro de esta funci칩n.

Luego, se calcula la potencia de cada se침al utilizando la funci칩n `potenciaDeSe침al`, que toma como entrada los datos de `voz` y `ruido`. Esta funci칩n devuelve dos valores: `potencia_voz` y `potencia_ruido`, que representan la potencia de las se침ales de voz y ruido, respectivamente. La potencia se determina como el promedio del cuadrado de los valores de la se침al.

Con las potencias calculadas, se procede a calcular el SNR en decibelios usando la f칩rmula:

![Agregar](potencia.png)


La funci칩n `np.log10` calcula el logaritmo en base 10, y el resultado se multiplica por 10 para expresar el SNR en decibelios.


```c
# Funci칩n para calcular la relaci칩n se침al-ruido (SNR) para cada archivo
def opcion_calcular_snr():
    for i in range(3):
        voz, sr = loadAudio(audio_voces[i])
        ruido, sr = loadAudio(audio_ruido[i])
        potencia_voz, potencia_ruido = potenciaDeSe침al(voz, ruido)
        snr = 10.0 * np.log10(potencia_voz / potencia_ruido)  # Calcula el SNR en decibelios
        print(f"SNR para {audio_voces[i]}: {snr:.2f} dB")
```

SNR para voz_mama.wav: 15.20 dB
SNR para voz_mari.wav: 18.38 dB
### **An치lisis del SNR**
1. SNR para voz_mama.wav: 15.20 dB

Un SNR de 15.20 dB indica que la se침al de voz en el archivo voz_mama.wav es m치s fuerte que el ruido, pero el nivel de ruido es todav칤a notable en comparaci칩n con la se침al. Este valor se encuentra en el rango donde la se침al es audiblemente clara pero el ruido es perceptible. En aplicaciones pr치cticas, esto podr칤a significar que la calidad del audio es aceptable pero podr칤a haber una cierta interferencia o distracci칩n causada por el ruido.

2. SNR para voz_mari.wav: 18.38 dB

Un SNR de 18.38 dB es superior al valor anterior y sugiere que la se침al de voz en el archivo voz_mari.wav es a칰n m치s clara en comparaci칩n con el ruido. Aunque el ruido sigue presente, su impacto es menor en comparaci칩n con voz_mama.wav. Este valor de SNR indica una mejor calidad de la se침al, con la voz siendo m치s prominente y menos afectada por el ruido de fondo. La calidad es bastante buena, y la interferencia del ruido es menos significativa.


Comparando ambos valores, voz_mari.wav tiene un SNR m치s alto (18.38 dB) que voz_mama.wav (15.20 dB), lo que implica que la se침al de voz en voz_mari.wav es relativamente m치s clara y menos interferida por el ruido. Esto puede ser el resultado de una grabaci칩n de mejor calidad o una menor presencia de ruido en voz_mari.wav.

<a name="menu"></a> 
## Menu

### **Men칰 Interactivo**

La funci칩n `mostrar_menu` muestra un men칰 con opciones disponibles para el usuario. Cada opci칩n corresponde a una funcionalidad espec칤fica relacionada con el procesamiento de archivos de audio, como cargar y reproducir un archivo, graficar y analizar el espectro de un archivo, mezclar voz y ruido, aplicar ICA para separar se침ales, calcular la relaci칩n se침al-ruido (SNR), o salir del programa. El men칰 ofrece una forma clara de seleccionar la acci칩n deseada.

### **Selecci칩n de Archivos de Audio**

La funci칩n `seleccionar_audio` permite al usuario elegir un archivo de audio de una lista. Imprime las opciones disponibles y solicita al usuario que seleccione un archivo mediante un n칰mero. Despu칠s de la selecci칩n, la funci칩n valida la opci칩n elegida y devuelve el archivo seleccionado. Si la opci칩n no es v치lida, la funci칩n muestra un mensaje de error y devuelve `None`. Esta funci칩n es 칰til para interactuar con listas de archivos y seleccionar el archivo que se desea procesar.

### **Carga y Reproducci칩n de Audio**

La funci칩n `opcion_cargar_reproducir` utiliza `seleccionar_audio` para elegir un archivo de voz y luego carga y reproduce el archivo seleccionado. La carga se realiza mediante la funci칩n `loadAudio`, y la reproducci칩n se lleva a cabo con la funci칩n `playAudio`. Esto permite al usuario escuchar el archivo de audio elegido.

### **Gr치fica y An치lisis Espectral**

La funci칩n `opcion_graficar_analizar` tambi칠n utiliza `seleccionar_audio` para elegir un archivo de voz. Una vez seleccionado, la funci칩n carga el archivo y genera dos tipos de an치lisis: una gr치fica de la forma de onda utilizando `graficarSonido` y un an치lisis espectral usando `analisisEspectral`. Esto proporciona una representaci칩n visual de la se침al y su contenido en frecuencia.

### **Mezcla de Voz y Ruido**

La funci칩n `opcion_mezclar` permite al usuario seleccionar archivos de voz y ruido, y luego mezcla estas se침ales utilizando la funci칩n `mezclarVoces`. La se침al mezclada se grafica y analiza espectralmente, y luego se reproduce. Este proceso muestra c칩mo la voz y el ruido se combinan en un solo archivo de audio.

### **Aplicaci칩n de ICA y Separaci칩n de Se침ales**

La funci칩n `opcion_aplicar_ica` utiliza ICA para separar las se침ales de voz y ruido. Primero, mezcla las se침ales seleccionadas, aplica ICA para separar las componentes y luego identifica cu치l de las componentes es la voz usando `identificar_voz`. La voz separada se grafica y se analiza espectralmente, y se reproduce. Adem치s, calcula el SNR de la voz separada en comparaci칩n con el ruido original, mostrando as칤 la calidad de la separaci칩n.

### **C치lculo del SNR para Cada Archivo**

La funci칩n `opcion_calcular_snr` calcula el SNR para cada archivo de voz en la lista `audio_voces` en comparaci칩n con los archivos de ruido en `audio_ruido`. Para cada par de archivos, calcula la potencia de la voz y del ruido, y luego determina el SNR en decibelios. Este c치lculo ayuda a evaluar la calidad de la se침al de voz en comparaci칩n con el ruido.

### **Bucle Principal del Men칰**

La funci칩n `main` contiene el bucle principal del programa, que muestra el men칰 y ejecuta la opci칩n seleccionada por el usuario. El bucle contin칰a ejecut치ndose hasta que el usuario elige la opci칩n de salir (`6`). Dependiendo de la opci칩n seleccionada, llama a la funci칩n correspondiente (`opcion_cargar_reproducir`, `opcion_graficar_analizar`, etc.). Si el usuario ingresa una opci칩n no v치lida, se muestra un mensaje de error. Al seleccionar salir, el bucle se rompe y el programa termina.

### **Ejecuci칩n del Programa**

Finalmente, el bloque `if __name__ == "__main__":` asegura que la funci칩n `main` se ejecute solo si el script se ejecuta directamente, y no cuando se importe como un m칩dulo en otro script.

```c
# Men칰 interactivo para seleccionar opciones
def mostrar_menu():
    print("\nMen칰 de Opciones:")
    print("1. Cargar y reproducir un archivo de audio")
    print("2. Graficar y analizar espectralmente un archivo de audio")
    print("3. Mezclar voz y ruido")
    print("4. Aplicar ICA para separar se침ales")
    print("5. Calcular SNR (Relaci칩n Se침al-Ruido)")
    print("6. Salir")

# Funci칩n para seleccionar un archivo de audio de una lista
def seleccionar_audio(lista_audios, tipo):
    print(f"\nSeleccione un {tipo}:")
    for i, archivo in enumerate(lista_audios):
        print(f"{i+1}. {archivo}")
    
    seleccion = int(input("Seleccione una opci칩n (1-3): ")) - 1
    if seleccion < 0 or seleccion >= len(lista_audios):
        print("Opci칩n no v치lida.")
        return None
    return lista_audios[seleccion]  # Devuelve el archivo seleccionado

# Funci칩n para cargar y reproducir un archivo de audio
def opcion_cargar_reproducir():
    archivo = seleccionar_audio(audio_voces, "archivo de voz")
    if archivo:
        data, sr = loadAudio(archivo)
        playAudio(data, sr)

# Funci칩n para graficar y analizar un archivo de audio
def opcion_graficar_analizar():
    archivo = seleccionar_audio(audio_voces, "archivo de voz")
    if archivo:
        data, sr = loadAudio(archivo)
        graficarSonido(data, sr, title=f"Forma de onda de {archivo}")
        analisisEspectral(data, sr, title=f"Espectro de {archivo}")

# Funci칩n para mezclar un archivo de voz y un archivo de ruido
def opcion_mezclar():
    voz = seleccionar_audio(audio_voces, "voz")
    ruido = seleccionar_audio(audio_ruido, "ruido")
    
    if voz and ruido:
        data_mezclada, sr_mezclada = mezclarVoces(voz, ruido)
        graficarSonido(data_mezclada[:, 0], sr_mezclada, "Se침al mezclada - Voz y Ruido")
        analisisEspectral(data_mezclada[:, 0], sr_mezclada, "Espectro - Se침al mezclada")
        playAudio(data_mezclada[:, 0], sr_mezclada)

# Funci칩n para aplicar ICA y separar la voz
def opcion_aplicar_ica():
    voz = seleccionar_audio(audio_voces, "voz")
    ruido = seleccionar_audio(audio_ruido, "ruido")
    
    if voz and ruido:
        data_mezclada, sr_mezclada = mezclarVoces(voz, ruido)
        se침ales_separadas = aplicar_ica(data_mezclada)
        
        # Identificar y reproducir solo la componente que parece ser la voz
        voz_separada = identificar_voz(se침ales_separadas, sr_mezclada)
        if voz_separada is not None:
            graficarSonido(voz_separada, sr_mezclada, "Voz Separada")
            analisisEspectral(voz_separada, sr_mezclada, "Espectro de la voz separada")
            print("Reproduciendo voz separada...")
            playAudio(voz_separada, sr_mezclada)
            
            # Cargar el ruido original para el c치lculo del SNR
            ruido_original, sr_ruido = loadAudio(ruido)  # Cargar los datos de ruido
            
            # Ajustar el tama침o del ruido a la longitud de la voz separada
            min_len = min(len(voz_separada), len(ruido_original))
            voz_separada = voz_separada[:min_len]
            ruido_original = ruido_original[:min_len]
            
            # Calcular la potencia de la voz separada y el ruido
            potencia_voz_separada = np.var(voz_separada)  # Varianza como estimaci칩n de potencia
            potencia_ruido = np.mean(ruido_original**2)  # Potencia del ruido
            
            # Calcular el SNR
            snr = 10.0 * np.log10(potencia_voz_separada / potencia_ruido)
            print(f"SNR para la voz separada: {snr:.2f} dB")

# Funci칩n para calcular la relaci칩n se침al-ruido (SNR) para cada archivo
def opcion_calcular_snr():
    for i in range(3):
        voz, sr = loadAudio(audio_voces[i])
        ruido, sr = loadAudio(audio_ruido[i])
        potencia_voz, potencia_ruido = potenciaDeSe침al(voz, ruido)
        snr = 10.0 * np.log10(potencia_voz / potencia_ruido)  # Calcula el SNR en decibelios
        print(f"SNR para {audio_voces[i]}: {snr:.2f} dB")

# Bucle principal del men칰
def main():
    while True:
        mostrar_menu()  # Muestra el men칰 de opciones
        opcion = input("\nSeleccione una opci칩n (1-6): ")
        
        # Ejecuta la opci칩n seleccionada
        if opcion == "1":
            opcion_cargar_reproducir()
        elif opcion == "2":
            opcion_graficar_analizar()
        elif opcion == "3":
            opcion_mezclar()
        elif opcion == "4":
            opcion_aplicar_ica()
        elif opcion == "5":
            opcion_calcular_snr()
        elif opcion == "6":
            print("Saliendo...")
            break  # Sale del bucle y termina el programa
        else:
            print("Opci칩n no v치lida, intente de nuevo.")

if __name__ == "__main__":
    main()  # Ejecuta la funci칩n principal


```

<a name="analisis"></a> 
## Analisis

![Agregar](analisis.png)

### An치lisis de la imagen:

#### Parte superior (Ondas en el tiempo):
En la parte superior de la imagen, se visualizan tres se침ales de audio, representadas en el dominio del tiempo. Las dos primeras gr치ficas muestran las **se침ales mezcladas** ("Mezcla mama" y "Mezcla mari"), que son combinaciones de dos fuentes de audio (voces) con ruido adicional. Estas se침ales son m치s ca칩ticas debido a la combinaci칩n de m칰ltiples fuentes, lo que sugiere la interferencia entre las voces y el ruido. En la tercera gr치fica, se muestra la **voz separada de Mari**, que tiene una forma de onda m치s limpia y regular. Esto indica que, tras aplicar un algoritmo de **An치lisis de Componentes Independientes (ICA)** , se ha conseguido extraer la se침al de la voz de Mari de manera efectiva, reduciendo el ruido y las interferencias de otras fuentes.

La principal idea del ICA es que las se침ales independientes pueden separarse mediante la maximizaci칩n de su independencia estad칤stica, lo cual parece haberse logrado en la gr치fica de la se침al separada de Mari. Se puede observar que las se침al recuperada (Voz Mari) es bastante similar a las original. Sin embargo, es importante destacar que una limitaci칩n del m칠todo ICA es su incapacidad para determinar la varianza de las componentes independientes que forman parte de la mezcla, lo que provoca una diferencia en la amplitud original de las fuentes sonoras. Adem치s, es relevante mencionar que cuando alguna de las se침ales mezcladas contiene pausas o silencios, durante la separaci칩n estos silencios pueden incluir sonidos de otras clases, aunque la se침al principal sigue siendo claramente comprensible.


#### Parte inferior (Espectros de frecuencia):
En la parte inferior de la imagen, se presentan los **espectros de frecuencia** de las se침ales mostradas arriba. El espectro de frecuencia permite analizar c칩mo la energ칤a de una se침al est치 distribuida a trav칠s de diferentes frecuencias. Los primeros dos gr치ficos muestran los **espectros de las se침ales mezcladas** ("mezcla mama" y "mezcla mari"). Ambos espectros muestran picos en diferentes bandas de frecuencia, lo cual indica que las se침ales mezcladas contienen componentes tanto de las voces como del ruido. La mezcla de estas se침ales en el espectro de frecuencia puede complicar el proceso de separaci칩n, ya que no siempre es trivial distinguir entre los componentes de voz y los de ruido.

El tercer gr치fico muestra el **espectro de la voz separada de Mari**. Aqu칤, los picos m치s altos en el espectro corresponden a las frecuencias caracter칤sticas de la voz humana, y la presencia de ruido es notablemente menor en comparaci칩n con las mezclas originales. Esto sugiere que el m칠todo de separaci칩n ha logrado atenuar significativamente el ruido, permitiendo una extracci칩n m치s pura de la se침al de voz. Seg칰n el primer archivo, uno de los objetivos del an치lisis de se침ales y muestreo compresivo es recuperar se침ales de audio limpias en situaciones donde haya interferencias, lo que se refleja claramente en esta parte del an치lisis.

#### Relaci칩n con los valores de SNR:
La Relaci칩n Se침al a Ruido (SNR) es una m칠trica clave para evaluar la calidad de la separaci칩n de se침ales. Los valores de SNR proporcionados indican lo bien que el algoritmo ha separado la se침al deseada del ruido. Para las primeras dos se침ales separadas, los valores de SNR son **44.62 dB** y **45.37 dB**, lo que representa una separaci칩n de alta calidad con muy poco ruido residual. Estos valores son consistentes con lo que se espera en una separaci칩n de se침ales efectiva, como se menciona en el archivo sobre el uso del ICA para extraer se침ales de audio. El archivo tambi칠n menciona c칩mo el rendimiento del sistema se puede evaluar mediante medidas como el SNR.

Sin embargo, el tercer valor de SNR para la se침al "voz_mari.wav" es de **18.38 dB**, un valor considerablemente m치s bajo. Esto indica que, aunque la se침al fue separada, a칰n existe un nivel m치s alto de ruido en la se침al final en comparaci칩n con las otras dos. El primer archivo sugiere que las t칠cnicas de procesamiento pueden verse limitadas por la complejidad de las se침ales mezcladas, lo cual podr칤a explicar este valor m치s bajo de SNR.

<a name="contacto"></a> 
## Contacto
* Creado por [Marianitex](https://github.com/Marianitex) - s칤gueme en mis redes sociales como @_mariana.higuera











